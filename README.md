<h1 align="center">
  <br>
  edugrad
  <br>
</h1>

<h4 align="center">Touching the surface of automatic differentation.</h4>


* A asks B "could you please explain backpropagation to me with a simple example?".
* B, aware of one's fear of failure thinks *it's been so long since my introduction to machine learning* and quickly responds "I have to be somewhere, maybe ask C?".
* B gets home and proves to oneself that one can still work out a simple backpropagation example, then proceeds to think about how ML frameworks do this automatically.
* B goes to bed knowing one is prepared for such question and starts having nightmares in directed acyclic graphs.

## Introduction

Please refer to the [mlp.py](examples/mlp.py) example.

## References

* [March 17, 2015 - A Step by Step Backpropagation Example by Matt Mazur](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)

* [Automatic Differentiation with torch.autograd by PyTorch](https://pytorch.org/tutorials/beginner/basics/autograd_tutorial.html#:~:text=This%20happens%20because%20when%20doing,leaf%20nodes%20of%20computational%20graph.)

* [Automatic Differentiation Explained](https://avinashselvam.medium.com/automatic-differentiation-explained-9f02c74e9a90)

* [Automatic differentation](https://en.wikipedia.org/wiki/Automatic_differentiation)

* [Automatic differentiation from scratch by esciencecenter](https://blog.esciencecenter.nl/automatic-differentiation-from-scratch-23d50c699555)

* [tinygrad](https://github.com/tinygrad/tinygrad)

