<h1 align="center">
  <br>
  edugrad
  <br>
</h1>

<h4 align="center">Learning about automatic differentiation.</h4>

## Introduction

This repository serves as an environment to learn about automatic differentiation and differentiable programming ("[software 2.0](https://karpathy.medium.com/software-2-0-a64152b37c35)") in general. Whilst the main focus is not teaching, it might be an interesting starting point for others who also don't know anything about these topics.


## Explanation 

A good resource to learn about differentiable programming and automatic differentiation is [The Elements of Differentiable Programming](https://arxiv.org/pdf/2403.14606) by Mathieu Blondel and Vincent Roulet. In what follows the core concepts that enable (efficient) automatic differentiation and other important information listed.

* By training parameterizing functional blocks (e.g. a neural network) using gradient-based optimization one can essentially approximate a functionality instead of manually writing the program.

* TODO: think about how software 2.0 allows for easier porting to hardware and is tinygrad an example?

* TODO: thoroughly explain when something is Differentiable, the limitations when something is not and how we can overcome this etc... ([karpathy has written about this for example in this post under Trainable Memory I/O title](https://karpathy.github.io/2016/05/31/rl/)


